[2025-01-29 16:34:04,285][numexpr.utils][INFO] - Note: NumExpr detected 12 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2025-01-29 16:34:04,285][numexpr.utils][INFO] - NumExpr defaulting to 8 threads.
[2025-01-29 16:34:08,297][flwr][INFO] - Starting Flower simulation, config: num_rounds=2, no round_timeout
[2025-01-29 16:34:08,354][filelock][INFO] - Lock 137828186605696 acquired on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/node_ip_address.json.lock
[2025-01-29 16:34:08,355][filelock][INFO] - Lock 137828186605696 released on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/node_ip_address.json.lock
[2025-01-29 16:34:08,355][filelock][INFO] - Lock 137828186689648 acquired on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186689648 released on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186691712 acquired on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186691712 released on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186689648 acquired on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186689648 released on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186234400 acquired on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,356][filelock][INFO] - Lock 137828186234400 released on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,357][filelock][INFO] - Lock 137828186233344 acquired on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:08,357][filelock][INFO] - Lock 137828186233344 released on /tmp/ray/session_2025-01-29_16-34-08_354406_62037/ports_by_node.json.lock
[2025-01-29 16:34:10,419][flwr][INFO] - Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'CPU': 12.0, 'node:192.168.1.11': 1.0, 'memory': 5163211163.0, 'object_store_memory': 2581605580.0}
[2025-01-29 16:34:10,420][flwr][INFO] - Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html
[2025-01-29 16:34:10,420][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 0}
[2025-01-29 16:34:10,430][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 6 actors
[2025-01-29 16:34:10,430][flwr][INFO] - [INIT]
[2025-01-29 16:34:10,430][flwr][INFO] - Requesting initial parameters from one random client
[2025-01-29 16:34:12,782][flwr][INFO] - Received initial parameters from one random client
[2025-01-29 16:34:12,782][flwr][INFO] - Starting evaluation of initial global parameters
[2025-01-29 16:34:37,439][flwr][ERROR] - too many values to unpack (expected 2)
[2025-01-29 16:34:37,440][flwr][ERROR] - Traceback (most recent call last):
  File "/home/vadi/anaconda3/lib/python3.8/site-packages/flwr/simulation/app.py", line 339, in start_simulation
    hist = run_fl(
  File "/home/vadi/anaconda3/lib/python3.8/site-packages/flwr/server/server.py", line 492, in run_fl
    hist, elapsed_time = server.fit(
  File "/home/vadi/anaconda3/lib/python3.8/site-packages/flwr/server/server.py", line 95, in fit
    res = self.strategy.evaluate(0, parameters=self.parameters)
  File "/home/vadi/anaconda3/lib/python3.8/site-packages/flwr/server/strategy/fedavg.py", line 170, in evaluate
    loss, metrics = eval_res
ValueError: too many values to unpack (expected 2)

[2025-01-29 16:34:37,441][flwr][ERROR] - Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 2, 'num_gpus': 0} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 2, 'num_gpus': 0}.
Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.
